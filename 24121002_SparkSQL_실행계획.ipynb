{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59ef1420-63de-4c2f-a151-e168e7fd8af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/10 14:52:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/10 14:52:25 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"24121002_SparkSQL_execution_plan\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff12cbf8-f19f-4ecf-985b-b1fa596af520",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", 'true')\\\n",
    "    .option('inferSchema', 'true')\\\n",
    "    .load('data/emp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fe22cf7-753f-48a1-899b-658eec9e5422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "| 7369| SMITH|    CLERK|7902|1980-12-17| 800|null|    20|\n",
      "| 7499| ALLEN| SALESMAN|7698|1981-02-20|1600| 300|    30|\n",
      "| 7521|  WARD| SALESMAN|7698|1981-02-22|1250| 500|    30|\n",
      "| 7566| JONES|  MANAGER|7839|1981-04-02|2975|null|    20|\n",
      "| 7654|MARTIN| SALESMAN|7698|1981-09-28|1250|1400|    30|\n",
      "| 7698| BLAKE|  MANAGER|7839|1981-05-01|2850|null|    30|\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|null|    10|\n",
      "| 7788| SCOTT|  ANALYST|7566|1987-04-19|3000|null|    20|\n",
      "| 7839|  KING|PRESIDENT|null|1981-11-17|5000|null|    10|\n",
      "| 7844|TURNER| SALESMAN|7698|1981-09-08|1500|   0|    30|\n",
      "| 7876| ADAMS|    CLERK|7788|1987-05-23|1100|null|    20|\n",
      "| 7900| JAMES|    CLERK|7698|1981-12-03| 950|null|    30|\n",
      "| 7902|  FORD|  ANALYST|7566|1981-12-03|3000|null|    20|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|null|    10|\n",
      "| 9292|  JACK|    CLERK|7782|1982-01-23|3200|null|    70|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93a4dec3-ee99-49db-afa0-ecb5b0bdb8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dept_df = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", 'true')\\\n",
    "    .option('inferSchema', 'true')\\\n",
    "    .load('data/dept.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6517924c-e72e-4f85-b8a2-9dce7525f4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- deptno: integer (nullable = true)\n",
      " |-- dname: string (nullable = true)\n",
      " |-- loc: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dept_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59f488f7-5eb5-4691-8015-97d2b71d79eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('emp_df_view')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27b2a30f-16eb-4dea-8a3d-5f64edf1ed02",
   "metadata": {},
   "outputs": [],
   "source": [
    "dept_df.createOrReplaceTempView('dept_df_view')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1418d89-b988-479e-a1ff-6e096cc36c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#뷰에서 조인\n",
    "join_query = '''\n",
    "select *\n",
    "from emp_df_view join dept_df_view on emp_df_view.deptno = dept_df_view.deptno\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46344875-e635-4adc-af33-7c93af5f5ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+------+----------+--------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|deptno|     dname|     loc|\n",
      "+-----+------+---------+----+----------+----+----+------+------+----------+--------+\n",
      "| 7369| SMITH|    CLERK|7902|1980-12-17| 800|null|    20|    20|  RESEARCH|  DALLAS|\n",
      "| 7499| ALLEN| SALESMAN|7698|1981-02-20|1600| 300|    30|    30|     SALES| CHICAGO|\n",
      "| 7521|  WARD| SALESMAN|7698|1981-02-22|1250| 500|    30|    30|     SALES| CHICAGO|\n",
      "| 7566| JONES|  MANAGER|7839|1981-04-02|2975|null|    20|    20|  RESEARCH|  DALLAS|\n",
      "| 7654|MARTIN| SALESMAN|7698|1981-09-28|1250|1400|    30|    30|     SALES| CHICAGO|\n",
      "| 7698| BLAKE|  MANAGER|7839|1981-05-01|2850|null|    30|    30|     SALES| CHICAGO|\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|null|    10|    10|ACCOUNTING|NEW YORK|\n",
      "| 7788| SCOTT|  ANALYST|7566|1987-04-19|3000|null|    20|    20|  RESEARCH|  DALLAS|\n",
      "| 7839|  KING|PRESIDENT|null|1981-11-17|5000|null|    10|    10|ACCOUNTING|NEW YORK|\n",
      "| 7844|TURNER| SALESMAN|7698|1981-09-08|1500|   0|    30|    30|     SALES| CHICAGO|\n",
      "| 7876| ADAMS|    CLERK|7788|1987-05-23|1100|null|    20|    20|  RESEARCH|  DALLAS|\n",
      "| 7900| JAMES|    CLERK|7698|1981-12-03| 950|null|    30|    30|     SALES| CHICAGO|\n",
      "| 7902|  FORD|  ANALYST|7566|1981-12-03|3000|null|    20|    20|  RESEARCH|  DALLAS|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|null|    10|    10|ACCOUNTING|NEW YORK|\n",
      "+-----+------+---------+----+----------+----+----+------+------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "viewEmpDept = spark.sql(join_query)\n",
    "viewEmpDept.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af265bb8-22a9-48e0-ac55-02c70750e9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewEmpDept.createOrReplaceTempView('viewEmpDept')\n",
    "#부서위치가 'NEW YORK' 인 직원 목록\n",
    "\n",
    "v_query = '''\n",
    "select * \n",
    "from viewEmpDept\n",
    "where loc = 'NEW YORK'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32bdccb8-9bfa-497d-a58c-1523f2e4b56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+------+----------+--------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|deptno|     dname|     loc|\n",
      "+-----+------+---------+----+----------+----+----+------+------+----------+--------+\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|null|    10|    10|ACCOUNTING|NEW YORK|\n",
      "| 7839|  KING|PRESIDENT|null|1981-11-17|5000|null|    10|    10|ACCOUNTING|NEW YORK|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|null|    10|    10|ACCOUNTING|NEW YORK|\n",
      "+-----+------+---------+----+----------+----+----+------+------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#case1\n",
    "spark.sql(v_query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db8e65fd-1ab2-48e7-8e32-6c18d80f4c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subquery\n",
    "\n",
    "q2 = '''\n",
    "select *\n",
    "from emp_df_view\n",
    "where deptno = (\n",
    "    select deptno\n",
    "    from dept_df_view\n",
    "    where loc='NEW YORK'\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e3447c3-936c-4e0b-8b63-c1314684d9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|null|    10|\n",
      "| 7839|  KING|PRESIDENT|null|1981-11-17|5000|null|    10|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|null|    10|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#case2\n",
    "spark.sql(q2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee88da7b-b644-4f2b-a6ad-3bc6a2c3fe22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) BroadcastHashJoin [deptno#23], [deptno#89], Inner, BuildRight, false\n",
      ":- *(2) Filter isnotnull(deptno#23)\n",
      ":  +- FileScan csv [empno#16,ename#17,job#18,mgr#19,hiredate#20,sal#21,comm#22,deptno#23] Batched: false, DataFilters: [isnotnull(deptno#23)], Format: CSV, Location: InMemoryFileIndex[file:/home/tutor/src/data/emp.csv], PartitionFilters: [], PushedFilters: [IsNotNull(deptno)], ReadSchema: struct<empno:int,ename:string,job:string,mgr:int,hiredate:string,sal:int,comm:int,deptno:int>\n",
      "+- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [id=#201]\n",
      "   +- *(1) Filter ((isnotnull(loc#91) AND (loc#91 = NEW YORK)) AND isnotnull(deptno#89))\n",
      "      +- FileScan csv [deptno#89,dname#90,loc#91] Batched: false, DataFilters: [isnotnull(loc#91), (loc#91 = NEW YORK), isnotnull(deptno#89)], Format: CSV, Location: InMemoryFileIndex[file:/home/tutor/src/data/dept.csv], PartitionFilters: [], PushedFilters: [IsNotNull(loc), EqualTo(loc,NEW YORK), IsNotNull(deptno)], ReadSchema: struct<deptno:int,dname:string,loc:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#case1 의 실행계획 - join\n",
    "spark.sql(v_query).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b2db437-f9a6-4ce5-974e-8b338a9aa556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Filter (isnotnull(deptno#23) AND (deptno#23 = Subquery scalar-subquery#292, [id=#220]))\n",
      ":  +- Subquery scalar-subquery#292, [id=#220]\n",
      ":     +- *(1) Project [deptno#89]\n",
      ":        +- *(1) Filter (isnotnull(loc#91) AND (loc#91 = NEW YORK))\n",
      ":           +- FileScan csv [deptno#89,loc#91] Batched: false, DataFilters: [isnotnull(loc#91), (loc#91 = NEW YORK)], Format: CSV, Location: InMemoryFileIndex[file:/home/tutor/src/data/dept.csv], PartitionFilters: [], PushedFilters: [IsNotNull(loc), EqualTo(loc,NEW YORK)], ReadSchema: struct<deptno:int,loc:string>\n",
      "+- FileScan csv [empno#16,ename#17,job#18,mgr#19,hiredate#20,sal#21,comm#22,deptno#23] Batched: false, DataFilters: [isnotnull(deptno#23)], Format: CSV, Location: InMemoryFileIndex[file:/home/tutor/src/data/emp.csv], PartitionFilters: [], PushedFilters: [IsNotNull(deptno)], ReadSchema: struct<empno:int,ename:string,job:string,mgr:int,hiredate:string,sal:int,comm:int,deptno:int>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#case2의 실행계획 - 서브쿼리\n",
    "spark.sql(q2).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6523e404-b723-46c3-a33a-541f81b37c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0c512cc-960b-451c-b035-b21cd605306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1924126f-1d96-404f-ba8c-cc243631e0b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(spark_start)",
   "language": "python",
   "name": "spark_start"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
