{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c307c8f-0f42-4a89-9bf7-0f0368172b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/11 10:28:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# SparkSession 생성\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"241211_01_SparkSQL_SQLtest\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f83a19-8e96-4f7d-9aaa-f406d88513a3",
   "metadata": {},
   "source": [
    "# 데이터 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b84eb469-b22d-4b79-ac75-a1742fec0f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "user_data = [\n",
    "    Row(user_id=1, username='A', address='서울'),\n",
    "    Row(user_id=2, username='B', address='대전'),\n",
    "    Row(user_id=3, username='C', address='경기도'),\n",
    "    Row(user_id=4, username='D', address=None),\n",
    "    Row(user_id=5, username='E', address=None),\n",
    "    Row(user_id=6, username='F', address='서울'),\n",
    "    Row(user_id=7, username='G', address='경기도'),\n",
    "    Row(user_id=8, username='H', address='대구'),\n",
    "    Row(user_id=9, username='I', address='부산'),\n",
    "    Row(user_id=10, username='J', address='전주'),\n",
    "    Row(user_id=11, username='K', address='광주')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "602610df-5f41-4560-bf06-383413718b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = spark.createDataFrame(user_data)\n",
    "user_df.createOrReplaceTempView('users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46c7f0a9-a121-4aae-bb31-b8bb27c11d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_data = [\n",
    "    Row(book_id=1, title=\"Book A\", author_fname=\"John\", author_lname=\"Doe\", pages=300, released_year=2005, stock_quantity=55),\n",
    "    Row(book_id=2, title=\"Book B\", author_fname=\"Jane\", author_lname=\"Smith\", pages=250, released_year=2010, stock_quantity=40),\n",
    "    Row(book_id=3, title=\"Book C\", author_fname=\"Emily\", author_lname=\"Jones\", pages=180, released_year=2015, stock_quantity=20),\n",
    "    Row(book_id=4, title=\"Book D\", author_fname=\"Chris\", author_lname=\"Brown\", pages=320, released_year=2012, stock_quantity=75),\n",
    "    Row(book_id=5, title=\"Book E\", author_fname=\"Anna\", author_lname=\"Davis\", pages=270, released_year=2008, stock_quantity=35)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f96266e5-cbc0-40c2-9785-ffc97401b6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df = spark.createDataFrame(books_data)\n",
    "books_df.createOrReplaceTempView('books')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f37c5c3-5d7b-43f0-9b7b-295e1d6a5774",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m query_users \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124mSELECT address, \u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124m\t   IF(address IN (\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m경기도\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m서울\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m), \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m수도권\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m지방\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) AS region \u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124mFROM users;\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241m.\u001b[39msql(query_users)\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "query_users = '''\n",
    "SELECT address, \n",
    "\t   IF(address IN ('경기도', '서울'), '수도권', '지방') AS region \n",
    "FROM users;\n",
    "'''\n",
    "spark.sql(query_users).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78812561-483c-4006-9e37-9c40d4c85e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# books table\n",
    "# stock_quantity >=50 '재고 많음', >= 30 '재고 중간', '재고 없음'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4815ee3f-1e1d-4890-8754-a13e154c17d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+\n",
      "|stock_quantity|quantity_level|\n",
      "+--------------+--------------+\n",
      "|            55|     재고 많음|\n",
      "|            40|     재고 중간|\n",
      "|            20|     재고 없음|\n",
      "|            75|     재고 많음|\n",
      "|            35|     재고 중간|\n",
      "+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "books_sql = '''\n",
    "SELECT stock_quantity, \n",
    "\t   IF(stock_quantity >= 50, '재고 많음',\n",
    "\t\t  IF(stock_quantity >= 30, '재고 중간', '재고 없음')) AS quantity_level\n",
    "FROM books;\n",
    "'''\n",
    "spark.sql(books_sql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42de8362-9ff5-4fa1-8a27-7689db913ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+\n",
      "|stock_quantity|quantity_level|\n",
      "+--------------+--------------+\n",
      "|            55|     재고 많음|\n",
      "|            40|     재고 중간|\n",
      "|            20|     재고 부족|\n",
      "|            75|     재고 많음|\n",
      "|            35|     재고 중간|\n",
      "+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "books_sql_1= '''\n",
    "SELECT stock_quantity, \n",
    "\t   CASE \n",
    "\t\t   WHEN stock_quantity >= 50 THEN '재고 많음'\n",
    "\t\t   WHEN stock_quantity >= 30 THEN '재고 중간'\n",
    "\t\t   ELSE '재고 부족'\n",
    "\t   END AS quantity_level\n",
    "FROM books;\n",
    "'''\n",
    "spark.sql(books_sql_1).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea6757f-9f63-4d83-bc68-1aeec77c07da",
   "metadata": {},
   "source": [
    "# 실행계획 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35c3e3db-098d-4223-9acb-6175e66db515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Project [stock_quantity#12L, if ((stock_quantity#12L >= 50)) 재고 많음 else if ((stock_quantity#12L >= 30)) 재고 중간 else 재고 없음 AS quantity_level#96]\n",
      "+- *(1) Scan ExistingRDD[book_id#6L,title#7,author_fname#8,author_lname#9,pages#10L,released_year#11L,stock_quantity#12L]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(books_sql).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be8a41f9-bd63-43e7-af9d-ad37ef640a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Project [stock_quantity#12L, CASE WHEN (stock_quantity#12L >= 50) THEN 재고 많음 WHEN (stock_quantity#12L >= 30) THEN 재고 중간 ELSE 재고 부족 END AS quantity_level#99]\n",
      "+- *(1) Scan ExistingRDD[book_id#6L,title#7,author_fname#8,author_lname#9,pages#10L,released_year#11L,stock_quantity#12L]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(books_sql_1).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f63c8d-9977-4a9c-903c-c85194d0a39f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c33d2fa0-32ce-424e-bf73-20bf94c33243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) HashAggregate(keys=[author_lname#9], functions=[])\n",
      "+- Exchange hashpartitioning(author_lname#9, 200), ENSURE_REQUIREMENTS, [id=#111]\n",
      "   +- *(1) HashAggregate(keys=[author_lname#9], functions=[])\n",
      "      +- *(1) Project [author_lname#9]\n",
      "         +- *(1) Scan ExistingRDD[book_id#6L,title#7,author_fname#8,author_lname#9,pages#10L,released_year#11L,stock_quantity#12L]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "books_sql_2 = '''\n",
    "select distinct author_lname from books;\n",
    "'''\n",
    "spark.sql(books_sql_2).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18097151-f156-49bc-827c-edb805b9dbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|author_lname|\n",
      "+------------+\n",
      "|       Jones|\n",
      "|       Davis|\n",
      "|       Smith|\n",
      "|         Doe|\n",
      "|       Brown|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(books_sql_2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36aad6ea-09c7-435c-ad3f-e1109fdedd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) HashAggregate(keys=[author_lname#9], functions=[count(1)])\n",
      "+- Exchange hashpartitioning(author_lname#9, 200), ENSURE_REQUIREMENTS, [id=#158]\n",
      "   +- *(1) HashAggregate(keys=[author_lname#9], functions=[partial_count(1)])\n",
      "      +- *(1) Project [author_lname#9]\n",
      "         +- *(1) Scan ExistingRDD[book_id#6L,title#7,author_fname#8,author_lname#9,pages#10L,released_year#11L,stock_quantity#12L]\n",
      "\n",
      "\n",
      "+------------+--------+\n",
      "|author_lname|count(1)|\n",
      "+------------+--------+\n",
      "|       Jones|       1|\n",
      "|       Davis|       1|\n",
      "|       Smith|       1|\n",
      "|         Doe|       1|\n",
      "|       Brown|       1|\n",
      "+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "books_sql_3 = '''\n",
    "select author_lname, count(*)\n",
    "from books\n",
    "group by author_lname;\n",
    "'''\n",
    "spark.sql(books_sql_3).explain()\n",
    "spark.sql(books_sql_3).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8443a58-18a6-40db-9383-540ca8979d6d",
   "metadata": {},
   "source": [
    "# 데이터 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4328973d-9c77-47f5-a644-d4042b5c4bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# books 테이블 데이터에 borrowed_by 추가\n",
    "books_data_with_user = [\n",
    "    Row(book_id=1, title=\"Book A\", author_fname=\"John\", author_lname=\"Doe\", pages=300, released_year=2005, stock_quantity=55, borrowed_by=1),\n",
    "    Row(book_id=2, title=\"Book B\", author_fname=\"Jane\", author_lname=\"Smith\", pages=250, released_year=2010, stock_quantity=40, borrowed_by=2),\n",
    "    Row(book_id=3, title=\"Book C\", author_fname=\"Emily\", author_lname=\"Jones\", pages=180, released_year=2015, stock_quantity=20, borrowed_by=3),\n",
    "    Row(book_id=4, title=\"Book D\", author_fname=\"Chris\", author_lname=\"Brown\", pages=320, released_year=2012, stock_quantity=75, borrowed_by=None),\n",
    "    Row(book_id=5, title=\"Book E\", author_fname=\"Anna\", author_lname=\"Davis\", pages=270, released_year=2008, stock_quantity=35, borrowed_by=6)\n",
    "]\n",
    "\n",
    "# DataFrame 생성\n",
    "books_df_with_user = spark.createDataFrame(books_data_with_user)\n",
    "\n",
    "# Temp View 등록\n",
    "books_df_with_user.createOrReplaceTempView(\"books\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed51ecf-eff4-4994-ba45-4696ee59d9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # borrowed_by 컬럼 추가 및 데이터 입력\n",
    "# updated_books_df = books_df.withColumn(\n",
    "#     \"borrowed_by\",\n",
    "#     when(books_df.book_id == 1, 1)\n",
    "#     .when(books_df.book_id == 2, 2)\n",
    "#     .when(books_df.book_id == 3, 3)\n",
    "#     .when(books_df.book_id == 4, lit(None))\n",
    "#     .when(books_df.book_id == 5, 6)\n",
    "#     .otherwise(None)\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36acc867-a511-4340-ad99-69be249d02d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "|book_id| title|author_fname|author_lname|pages|released_year|stock_quantity|borrowed_by|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "|      1|Book A|        John|         Doe|  300|         2005|            55|          1|\n",
      "|      2|Book B|        Jane|       Smith|  250|         2010|            40|          2|\n",
      "|      3|Book C|       Emily|       Jones|  180|         2015|            20|          3|\n",
      "|      4|Book D|       Chris|       Brown|  320|         2012|            75|       null|\n",
      "|      5|Book E|        Anna|       Davis|  270|         2008|            35|          6|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "books_sql = '''\n",
    "SELECT *\n",
    "FROM books;\n",
    "'''\n",
    "spark.sql(books_sql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8085cf6a-0d5a-4a8d-b67a-75b532fec7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3509f952-29c3-453d-847b-daec9780bcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "|book_id| title|author_fname|author_lname|pages|released_year|stock_quantity|borrowed_by|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "|      1|Book A|        John|         Doe|  300|         2005|            55|          1|\n",
      "|      2|Book B|        Jane|       Smith|  250|         2010|            40|          2|\n",
      "|      3|Book C|       Emily|       Jones|  180|         2015|            50|          3|\n",
      "|      4|Book D|       Chris|       Brown|  320|         2012|            75|       null|\n",
      "|      5|Book E|        Anna|       Davis|  270|         2008|            35|          6|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#book_id = 3, stock_quantity=50으로 바꾼다. > 전처리 과정\n",
    "\n",
    "updated_books_df = books_df_with_user.withColumn(\n",
    "    \"stock_quantity\",\n",
    "    when(books_df_with_user.book_id == 3, 50).otherwise(books_df_with_user.stock_quantity)\n",
    ")\n",
    "updated_books_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89e6a010-6e95-4119-8a35-09c2caf0195e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n",
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "|book_id| title|author_fname|author_lname|pages|released_year|stock_quantity|borrowed_by|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "|      1|Book A|        John|         Doe|  300|         2005|            55|          1|\n",
      "|      2|Book B|        Jane|       Smith|  250|         2010|            40|          2|\n",
      "|      3|Book C|       Emily|       Jones|  180|         2015|            50|          3|\n",
      "|      4|Book D|       Chris|       Brown|  320|         2012|            75|       null|\n",
      "|      5|Book E|        Anna|       Davis|  270|         2008|            35|          6|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# stock_quantity * 10% 증가\n",
    "\n",
    "#뷰로 등록\n",
    "updated_books_df.createOrReplaceTempView(\"books\")\n",
    "spark.sql(\"select * from books\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2814c458-fc36-4407-bb21-4ea08bf8bcf4",
   "metadata": {},
   "source": [
    "# 데이터 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "180b2b11-835b-49ff-a861-b57c1361083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write 의 저장 mode : overwrite, append, ignore, error\n",
    "\n",
    "updated_books_df.write.csv(\"data/output/sqltest_updated_books.csv\", header=True, mode=\"overwrite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03f7528d-4718-4ec0-a7c0-3e778a065e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.write.csv(\"data/output/sqltest_updated_users.csv\", header=True, mode=\"overwrite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3814a57-865f-44c7-a9fc-380426f33e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_books_df1 = spark.read.csv(\"data/output/sqltest_updated_books.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28052e1e-c794-4ed8-89d9-83edd0689b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df1 = spark.read.csv(\"data/output/sqltest_updated_users.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03b0d3c1-b612-4691-91be-c67ee7856a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "|book_id| title|author_fname|author_lname|pages|released_year|stock_quantity|borrowed_by|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "|      3|Book C|       Emily|       Jones|  180|         2015|            50|          3|\n",
      "|      4|Book D|       Chris|       Brown|  320|         2012|            75|       null|\n",
      "|      5|Book E|        Anna|       Davis|  270|         2008|            35|          6|\n",
      "|      1|Book A|        John|         Doe|  300|         2005|            55|          1|\n",
      "|      2|Book B|        Jane|       Smith|  250|         2010|            40|          2|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "updated_books_df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e388a96e-b01f-4289-b08a-b6c11e0305b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-------+\n",
      "|user_id|username|address|\n",
      "+-------+--------+-------+\n",
      "|      6|       F|   서울|\n",
      "|      7|       G| 경기도|\n",
      "|      8|       H|   대구|\n",
      "|      9|       I|   부산|\n",
      "|     10|       J|   전주|\n",
      "|     11|       K|   광주|\n",
      "|      1|       A|   서울|\n",
      "|      2|       B|   대전|\n",
      "|      3|       C| 경기도|\n",
      "|      4|       D|   null|\n",
      "|      5|       E|   null|\n",
      "+-------+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e0ad30-2162-4b0e-a171-5943fb3aefc1",
   "metadata": {},
   "source": [
    "# 조인 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9adcb4b6-a184-4962-b198-407e8b252f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------+------------+--------+-------+\n",
      "|book_id| title|author_fname|author_lname|username|address|\n",
      "+-------+------+------------+------------+--------+-------+\n",
      "|      5|Book E|        Anna|       Davis|       F|   서울|\n",
      "|      1|Book A|        John|         Doe|       A|   서울|\n",
      "|      3|Book C|       Emily|       Jones|       C| 경기도|\n",
      "|      2|Book B|        Jane|       Smith|       B|   대전|\n",
      "+-------+------+------------+------------+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#book_id, title, author_fname, author_lname, username, address\n",
    "join_query = '''\n",
    "SELECT book_id, title, author_fname, author_lname, username, address\n",
    "FROM books b INNER JOIN users u ON b.borrowed_by = u.user_id;\n",
    "'''\n",
    "spark.sql(join_query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696ecf17-d146-4652-93ea-a1c1c72bc684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# books LEFT JOIN users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b6006d-747c-4b51-843b-679251731232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자의 책 대여 목록 > 전체 사용자 > 대여한 정보가 있으면 나오면, 없으면 NULL\n",
    "# books RIGHT JOIN users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4530dc-8502-469b-8c35-6e09787cad53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정지역=서울에 거주하는 사용자가 대여한 책 목록\n",
    "join_query = '''\n",
    "SELECT book_id, title, author_fname, author_lname, username, address\n",
    "FROM books b LEFT JOIN users u ON b.borrowed_by = u.user_id\n",
    "WHERE u.address = '서울';\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fcab0d-010a-4187-befc-2daf5993c053",
   "metadata": {},
   "outputs": [],
   "source": [
    "#사용자별로 대여한 책 수\n",
    "join_query = '''\n",
    "SELECT user_id, username, count(book_id)\n",
    "FROM users u LEFT JOIN books b ON u.user_id = b.borrowed_by\n",
    "GROUP BY u.user_id, u.username;\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ebc3e35c-e447-4efa-b513-e96bbbe4e5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#book_category > 300 이상이면 Long, Short\n",
    "join_query = '''\n",
    "SELECT book_id,title, pages, CASE \n",
    "                        WHEN pages>=300 THEN 'Long' ELSE 'Short'\n",
    "                        END AS book_category\n",
    "FROM books;\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d9170b-2331-48ad-a349-1feb8b8d5990",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stock_quantity > 50 이상 '충분', 30 이상 '보통', 미만 '부족'\n",
    "'''\n",
    "SELECT book_id, title, stock_quantity, CASE WHEN stock_quantity>=50 THEN '충분'\n",
    "                                            WHEN stock_quantity>=30 THEN '보통'\n",
    "                                            ELSE '부족' END AS stock_status\n",
    "FROM books;\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2590d54-9e40-461f-8a83-a48c2cd730c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#책제목에 특정 키워드가 포함되어 있는지 확인할 때\n",
    "'''WHERE title LIKE '%A%'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df55c82-101d-4654-889b-a1c3262df18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#대여가 가장 많이 된 책의 작가를 조회\n",
    "'''\n",
    "SELECT author_fname, author_lname, count(book_id) as borrow_count\n",
    "FROM books \n",
    "GROUP BY author_fname, author_lname\n",
    "ORDER BY borrow_count DESC\n",
    "LIMIT 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d838b4-4519-43b9-9211-50ff728499a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#책의 발행 연도별 대여 현황: 발행 연도별로 대여된 책의 수를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30161f29-7bb3-4231-8935-fe1372a4c77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자의 지역별 대여된 책 수: 사용자 지역별로 대여된 책의 수를 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7d41be-ed16-40c1-99a5-345b8d2afe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대여되지 않은 책 중 가장 페이지 수가 많은 책: 대여되지 않은 책 중에서 페이지 수가 가장 많은 책을 조회합니다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "27a98e33-3f8b-44d5-bacf-e80a99ceb884",
   "metadata": {},
   "source": [
    "# 재고가 부족한 책과 대여 상태: 재고가 30개 미만인 책과 해당 책이 대여된 상태인지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b1da66-28cf-4116-a814-5e1dad8d6a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#실행계획, DAG 형태 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607e0618-7894-41c8-aebc-538e0446b181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv 로 save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6651111-7d05-49c0-a3f0-af8da98d3925",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535ced09-8ea8-4d54-96b4-efffffb65e67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(spark_start)",
   "language": "python",
   "name": "spark_start"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
